import os
import pandas as pd
from pathlib import Path

base_path = '/kaggle/input'

print("=== DIABETES DATASETS ===\n")

diabetes_csv = f"{base_path}/pima-indians-diabetes-database/diabetes.csv"
if os.path.exists(diabetes_csv):
    df = pd.read_csv(diabetes_csv)
    print(f"Pima Diabetes CSV: {df.shape}")
    print(f"Columns: {list(df.columns)}")
    print(f"Target distribution:\n{df['Outcome'].value_counts()}\n")

retinal_base = f"{base_path}/diabetic-retinopathy-224x224-2019-data"
colored_images = f"{retinal_base}/colored_images"
train_csv = f"{retinal_base}/train.csv"

if os.path.exists(colored_images):
    folders = sorted([f for f in os.listdir(colored_images) if os.path.isdir(os.path.join(colored_images, f))])
    print(f"Retinal Image Folders: {folders}")
    for folder in folders:
        count = len(os.listdir(os.path.join(colored_images, folder)))
        print(f"  {folder}: {count} images")

if os.path.exists(train_csv):
    df_train = pd.read_csv(train_csv)
    print(f"\nRetinal Labels CSV: {df_train.shape}")
    print(f"Columns: {list(df_train.columns)}")
    if 'diagnosis' in df_train.columns:
        print(f"Class distribution:\n{df_train['diagnosis'].value_counts()}\n")

print("\n=== HEART DISEASE DATASETS ===\n")

heart_csv = f"{base_path}/heart-disease-dataset/heart.csv"
if os.path.exists(heart_csv):
    df_heart = pd.read_csv(heart_csv)
    print(f"Heart Disease CSV: {df_heart.shape}")
    print(f"Columns: {list(df_heart.columns)}")
    print(f"Target distribution:\n{df_heart['target'].value_counts()}\n")

ecg_base = f"{base_path}/ecg-analysis/ecg_data_new_version/ecg data new version"
if os.path.exists(ecg_base):
    ecg_folders = sorted([f for f in os.listdir(ecg_base) if os.path.isdir(os.path.join(ecg_base, f))])
    print(f"ECG Image Folders: {ecg_folders}")
    for folder in ecg_folders:
        folder_path = os.path.join(ecg_base, folder)
        count = len([f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))])
        print(f"  {folder}: {count} images")


import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision
from torchvision import transforms, models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import pickle
import warnings
warnings.filterwarnings('ignore')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

DIABETES_CSV = '/kaggle/input/pima-indians-diabetes-database/diabetes.csv'
HEART_CSV = '/kaggle/input/heart-disease-dataset/heart.csv'
RETINAL_BASE = '/kaggle/input/diabetic-retinopathy-224x224-2019-data/colored_images'
ECG_BASE = '/kaggle/input/ecg-analysis/ecg_data_new_version/ecg data new version'
RETINAL_LABELS = '/kaggle/input/diabetic-retinopathy-224x224-2019-data/train.csv'

IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 15
SEED = 42

np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)

print("\nPaths and seeds configured successfully")


df_diabetes = pd.read_csv(DIABETES_CSV)

print("Diabetes CSV Dataset")
print(f"Shape: {df_diabetes.shape}")
print(f"\nFirst few rows:\n{df_diabetes.head()}")
print(f"\nData Info:")
print(df_diabetes.info())
print(f"\nMissing values:\n{df_diabetes.isnull().sum()}")
print(f"\nStatistical Summary:\n{df_diabetes.describe()}")

X_diabetes = df_diabetes.drop('Outcome', axis=1)
y_diabetes = df_diabetes['Outcome']

scaler_diabetes = StandardScaler()
X_diabetes_scaled = scaler_diabetes.fit_transform(X_diabetes)

X_train_diabetes, X_test_diabetes, y_train_diabetes, y_test_diabetes = train_test_split(
    X_diabetes_scaled, y_diabetes, test_size=0.2, random_state=SEED, stratify=y_diabetes
)

print(f"\nTrain set: {X_train_diabetes.shape}, Test set: {X_test_diabetes.shape}")
print(f"Train distribution:\n{pd.Series(y_train_diabetes).value_counts()}")
print(f"Test distribution:\n{pd.Series(y_test_diabetes).value_counts()}")


xgb_diabetes = xgb.XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=SEED,
    eval_metric='logloss'
)

xgb_diabetes.fit(X_train_diabetes, y_train_diabetes)

y_pred_diabetes = xgb_diabetes.predict(X_test_diabetes)
y_pred_proba_diabetes = xgb_diabetes.predict_proba(X_test_diabetes)

accuracy = accuracy_score(y_test_diabetes, y_pred_diabetes)
print(f"Diabetes XGBoost Accuracy: {accuracy:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test_diabetes, y_pred_diabetes)}")
print(f"\nConfusion Matrix:\n{confusion_matrix(y_test_diabetes, y_pred_diabetes)}")

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test_diabetes, y_pred_diabetes), annot=True, fmt='d', cmap='Blues')
plt.title('Diabetes XGBoost Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

with open('diabetes_xgboost_model.pkl', 'wb') as f:
    pickle.dump(xgb_diabetes, f)
with open('diabetes_scaler.pkl', 'wb') as f:
    pickle.dump(scaler_diabetes, f)

print("\nDiabetes XGBoost model and scaler saved")


df_heart = pd.read_csv(HEART_CSV)

print("Heart Disease CSV Dataset")
print(f"Shape: {df_heart.shape}")
print(f"\nFirst few rows:\n{df_heart.head()}")
print(f"\nData Info:")
print(df_heart.info())
print(f"\nMissing values:\n{df_heart.isnull().sum()}")
print(f"\nStatistical Summary:\n{df_heart.describe()}")

X_heart = df_heart.drop('target', axis=1)
y_heart = df_heart['target']

scaler_heart = StandardScaler()
X_heart_scaled = scaler_heart.fit_transform(X_heart)

X_train_heart, X_test_heart, y_train_heart, y_test_heart = train_test_split(
    X_heart_scaled, y_heart, test_size=0.2, random_state=SEED, stratify=y_heart
)

print(f"\nTrain set: {X_train_heart.shape}, Test set: {X_test_heart.shape}")
print(f"Train distribution:\n{pd.Series(y_train_heart).value_counts()}")
print(f"Test distribution:\n{pd.Series(y_test_heart).value_counts()}")


xgb_heart = xgb.XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=SEED,
    eval_metric='logloss'
)

xgb_heart.fit(X_train_heart, y_train_heart)

y_pred_heart = xgb_heart.predict(X_test_heart)
y_pred_proba_heart = xgb_heart.predict_proba(X_test_heart)

accuracy = accuracy_score(y_test_heart, y_pred_heart)
print(f"Heart Disease XGBoost Accuracy: {accuracy:.4f}")
print(f"\nClassification Report:\n{classification_report(y_test_heart, y_pred_heart)}")
print(f"\nConfusion Matrix:\n{confusion_matrix(y_test_heart, y_pred_heart)}")

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test_heart, y_pred_heart), annot=True, fmt='d', cmap='Greens')
plt.title('Heart Disease XGBoost Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

with open('heart_xgboost_model.pkl', 'wb') as f:
    pickle.dump(xgb_heart, f)
with open('heart_scaler.pkl', 'wb') as f:
    pickle.dump(scaler_heart, f)

print("\nHeart Disease XGBoost model and scaler saved")


retinal_labels_df = pd.read_csv(RETINAL_LABELS)
print("Retinal Labels DataFrame:")
print(retinal_labels_df.head())
print(f"\nShape: {retinal_labels_df.shape}")
print(f"\nOriginal class distribution:\n{retinal_labels_df['diagnosis'].value_counts().sort_index()}")

retinal_labels_df['binary_label'] = (retinal_labels_df['diagnosis'] > 0).astype(int)
print(f"\nBinary class distribution:\n{retinal_labels_df['binary_label'].value_counts()}")

image_paths = []
labels = []

class_folders = {
    0: 'No_DR',
    1: 'Mild',
    2: 'Moderate',
    3: 'Severe',
    4: 'Proliferate_DR'
}

for idx, row in retinal_labels_df.iterrows():
    img_id = row['id_code']
    label = row['binary_label']
    orig_label = row['diagnosis']
    folder_name = class_folders[orig_label]
    img_path = f"{RETINAL_BASE}/{folder_name}/{img_id}.png"
    
    if os.path.exists(img_path):
        image_paths.append(img_path)
        labels.append(label)

print(f"\nTotal images found: {len(image_paths)}")
print(f"Binary label distribution:\n{pd.Series(labels).value_counts()}")

retinal_df = pd.DataFrame({'image_path': image_paths, 'label': labels})

train_retinal_df, test_retinal_df = train_test_split(
    retinal_df, test_size=0.2, random_state=SEED, stratify=retinal_df['label']
)

print(f"\nTrain images: {len(train_retinal_df)}, Test images: {len(test_retinal_df)}")
print(f"Train distribution:\n{train_retinal_df['label'].value_counts()}")
print(f"Test distribution:\n{test_retinal_df['label'].value_counts()}")


class RetinalDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
    
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx]['image_path']
        label = self.dataframe.iloc[idx]['label']
        
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_dataset = RetinalDataset(train_retinal_df, transform=train_transform)
test_dataset = RetinalDataset(test_retinal_df, transform=test_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

print(f"Train batches: {len(train_loader)}")
print(f"Test batches: {len(test_loader)}")
print(f"Train dataset size: {len(train_dataset)}")
print(f"Test dataset size: {len(test_dataset)}")


model_retinal = models.efficientnet_b0(weights='IMAGENET1K_V1')
num_features = model_retinal.classifier[1].in_features
model_retinal.classifier = nn.Sequential(
    nn.Dropout(0.3),
    nn.Linear(num_features, 128),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(128, 2)
)

model_retinal = model_retinal.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_retinal.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)

print("Starting training for Retinal Image Model...")
print(f"Model architecture:\n{model_retinal.classifier}")

train_losses = []
train_accs = []
val_losses = []
val_accs = []
best_val_acc = 0.0

for epoch in range(EPOCHS):
    model_retinal.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model_retinal(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    train_loss = running_loss / len(train_loader)
    train_acc = 100. * correct / total
    train_losses.append(train_loss)
    train_accs.append(train_acc)
    
    model_retinal.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model_retinal(images)
            loss = criterion(outputs, labels)
            
            val_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    val_loss = val_loss / len(test_loader)
    val_acc = 100. * correct / total
    val_losses.append(val_loss)
    val_accs.append(val_acc)
    
    scheduler.step(val_acc)
    
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model_retinal.state_dict(), 'diabetes_retinal_model.pth')
    
    print(f'Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%')

print(f"\nBest Validation Accuracy: {best_val_acc:.2f}%")
print("Retinal image model saved as diabetes_retinal_model.pth")


model_retinal.load_state_dict(torch.load('diabetes_retinal_model.pth'))
model_retinal.eval()

all_preds = []
all_labels = []
all_probs = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model_retinal(images)
        probs = torch.softmax(outputs, dim=1)
        _, predicted = outputs.max(1)
        
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

accuracy = accuracy_score(all_labels, all_preds)
print(f"Retinal Image Model Test Accuracy: {accuracy:.4f}")
print(f"\nClassification Report:\n{classification_report(all_labels, all_preds, target_names=['No DR', 'Has DR'])}")
print(f"\nConfusion Matrix:\n{confusion_matrix(all_labels, all_preds)}")

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(all_labels, all_preds), annot=True, fmt='d', cmap='Blues', xticklabels=['No DR', 'Has DR'], yticklabels=['No DR', 'Has DR'])
plt.title('Retinal Image Model Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_accs, label='Train Accuracy')
plt.plot(val_accs, label='Val Accuracy')
plt.title('Retinal Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.title('Retinal Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

print("\nRetinal image model evaluation completed")


ecg_image_paths = []
ecg_labels = []

ecg_class_mapping = {
    'normal_ecg_images': 0,
    'abnormal_heartbeat_ecg_images': 1,
    'myocardial_infarction_ecg_images': 1,
    'post_mi_history_ecg_images': 1
}

for class_folder, label in ecg_class_mapping.items():
    folder_path = os.path.join(ECG_BASE, class_folder)
    if os.path.exists(folder_path):
        for img_file in os.listdir(folder_path):
            if img_file.endswith(('.png', '.jpg', '.jpeg')):
                img_path = os.path.join(folder_path, img_file)
                ecg_image_paths.append(img_path)
                ecg_labels.append(label)

print(f"Total ECG images found: {len(ecg_image_paths)}")
print(f"Binary label distribution:\n{pd.Series(ecg_labels).value_counts()}")

ecg_df = pd.DataFrame({'image_path': ecg_image_paths, 'label': ecg_labels})

train_ecg_df, test_ecg_df = train_test_split(
    ecg_df, test_size=0.2, random_state=SEED, stratify=ecg_df['label']
)

print(f"\nTrain images: {len(train_ecg_df)}, Test images: {len(test_ecg_df)}")
print(f"Train distribution:\n{train_ecg_df['label'].value_counts()}")
print(f"Test distribution:\n{test_ecg_df['label'].value_counts()}")


class ECGDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
    
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx]['image_path']
        label = self.dataframe.iloc[idx]['label']
        
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

train_ecg_dataset = ECGDataset(train_ecg_df, transform=train_transform)
test_ecg_dataset = ECGDataset(test_ecg_df, transform=test_transform)

train_ecg_loader = DataLoader(train_ecg_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
test_ecg_loader = DataLoader(test_ecg_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)

print(f"Train batches: {len(train_ecg_loader)}")
print(f"Test batches: {len(test_ecg_loader)}")
print(f"Train dataset size: {len(train_ecg_dataset)}")
print(f"Test dataset size: {len(test_ecg_dataset)}")


model_ecg = models.resnet50(weights='IMAGENET1K_V1')
num_features = model_ecg.fc.in_features
model_ecg.fc = nn.Sequential(
    nn.Dropout(0.3),
    nn.Linear(num_features, 128),
    nn.ReLU(),
    nn.Dropout(0.2),
    nn.Linear(128, 2)
)

model_ecg = model_ecg.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model_ecg.parameters(), lr=0.0001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)

print("Starting training for ECG Image Model...")
print(f"Model architecture:\n{model_ecg.fc}")

train_losses_ecg = []
train_accs_ecg = []
val_losses_ecg = []
val_accs_ecg = []
best_val_acc_ecg = 0.0

for epoch in range(EPOCHS):
    model_ecg.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in train_ecg_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model_ecg(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    train_loss = running_loss / len(train_ecg_loader)
    train_acc = 100. * correct / total
    train_losses_ecg.append(train_loss)
    train_accs_ecg.append(train_acc)
    
    model_ecg.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in test_ecg_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model_ecg(images)
            loss = criterion(outputs, labels)
            
            val_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    val_loss = val_loss / len(test_ecg_loader)
    val_acc = 100. * correct / total
    val_losses_ecg.append(val_loss)
    val_accs_ecg.append(val_acc)
    
    scheduler.step(val_acc)
    
    if val_acc > best_val_acc_ecg:
        best_val_acc_ecg = val_acc
        torch.save(model_ecg.state_dict(), 'heart_ecg_model.pth')
    
    print(f'Epoch [{epoch+1}/{EPOCHS}] Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%')

print(f"\nBest Validation Accuracy: {best_val_acc_ecg:.2f}%")
print("ECG image model saved as heart_ecg_model.pth")


model_ecg.load_state_dict(torch.load('heart_ecg_model.pth'))
model_ecg.eval()

all_preds_ecg = []
all_labels_ecg = []
all_probs_ecg = []

with torch.no_grad():
    for images, labels in test_ecg_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model_ecg(images)
        probs = torch.softmax(outputs, dim=1)
        _, predicted = outputs.max(1)
        
        all_preds_ecg.extend(predicted.cpu().numpy())
        all_labels_ecg.extend(labels.cpu().numpy())
        all_probs_ecg.extend(probs.cpu().numpy())

accuracy = accuracy_score(all_labels_ecg, all_preds_ecg)
print(f"ECG Image Model Test Accuracy: {accuracy:.4f}")
print(f"\nClassification Report:\n{classification_report(all_labels_ecg, all_preds_ecg, target_names=['Normal', 'Heart Disease'])}")
print(f"\nConfusion Matrix:\n{confusion_matrix(all_labels_ecg, all_preds_ecg)}")

plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(all_labels_ecg, all_preds_ecg), annot=True, fmt='d', cmap='Greens', xticklabels=['Normal', 'Heart Disease'], yticklabels=['Normal', 'Heart Disease'])
plt.title('ECG Image Model Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_accs_ecg, label='Train Accuracy')
plt.plot(val_accs_ecg, label='Val Accuracy')
plt.title('ECG Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(train_losses_ecg, label='Train Loss')
plt.plot(val_losses_ecg, label='Val Loss')
plt.title('ECG Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

print("\nECG image model evaluation completed")


print("="*80)
print("MODEL TRAINING SUMMARY")
print("="*80)

print("\n1. DIABETES PREDICTION")
print("-" * 40)
print("Tabular Model (XGBoost):")
print(f"  - Test Accuracy: 77.92%")
print(f"  - Model saved: diabetes_xgboost_model.pkl")
print(f"  - Scaler saved: diabetes_scaler.pkl")

print("\nRetinal Image Model (EfficientNetB0):")
print(f"  - Test Accuracy: 98.23%")
print(f"  - Best Val Accuracy: 98.23%")
print(f"  - Model saved: diabetes_retinal_model.pth")

print("\n2. HEART DISEASE PREDICTION")
print("-" * 40)
print("Tabular Model (XGBoost):")
print(f"  - Test Accuracy: 100.00%")
print(f"  - Model saved: heart_xgboost_model.pkl")
print(f"  - Scaler saved: heart_scaler.pkl")

print("\nECG Image Model (ResNet50):")
print(f"  - Test Accuracy: 100.00%")
print(f"  - Best Val Accuracy: 100.00%")
print(f"  - Model saved: heart_ecg_model.pth")

print("\n" + "="*80)
print("ALL MODELS TRAINED AND SAVED SUCCESSFULLY")
print("="*80)

print("\nFiles to download for deployment:")
files_list = [
    'diabetes_xgboost_model.pkl',
    'diabetes_scaler.pkl',
    'diabetes_retinal_model.pth',
    'heart_xgboost_model.pkl',
    'heart_scaler.pkl',
    'heart_ecg_model.pth'
]

for i, file in enumerate(files_list, 1):
    print(f"{i}. {file}")


import sys
print("="*80)
print("PYTHON AND LIBRARY VERSIONS")
print("="*80)

print(f"\nPython: {sys.version}")
print(f"\nCore Libraries:")
print(f"  - NumPy: {np.__version__}")
print(f"  - Pandas: {pd.__version__}")

print(f"\nDeep Learning:")
print(f"  - PyTorch: {torch.__version__}")
print(f"  - TorchVision: {torchvision.__version__}")

print(f"\nMachine Learning:")
print(f"  - Scikit-learn: {__import__('sklearn').__version__}")
print(f"  - XGBoost: {xgb.__version__}")

print(f"\nVisualization:")
print(f"  - Matplotlib: {__import__('matplotlib').__version__}")
print(f"  - Seaborn: {sns.__version__}")

print(f"\nImage Processing:")
print(f"  - Pillow (PIL): {__import__('PIL').__version__}")

print(f"\nCUDA:")
print(f"  - CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"  - CUDA Version: {torch.version.cuda}")
    print(f"  - GPU Device: {torch.cuda.get_device_name(0)}")

print("\n" + "="*80)


get_ipython().getoutput("zip -r model.zip /kaggle/working")


from IPython.display import FileLink
FileLink(r'model.zi



